{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMjbGKw/+zoojHjVlaz6akj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Exam Python section"],"metadata":{"id":"uZasNHNTOMh2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDpRUrbFRJOa","executionInfo":{"status":"ok","timestamp":1748501104619,"user_tz":-120,"elapsed":20072,"user":{"displayName":"Gerard Martinez Canelles","userId":"00161740883111108037"}},"outputId":"fa8d7e34-0fb5-4299-d557-1b5d1c552b42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Understanding the dataset"],"metadata":{"id":"pGTgjXTzOc9r"}},{"cell_type":"markdown","source":["1.0) Import the main data analysis libraries such as pandas, numpy, matplotlib.pylot and seaborn (0.1 points)"],"metadata":{"id":"JrU_NNJJOdCP"}},{"cell_type":"code","source":[" # Your solution"],"metadata":{"id":"5L9049IiOWU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","1.1) Read the dataset named `ai_assistants.xlsx` from the Datasets folder using `pd.read_excel()`, and store it in a variable named `df`. (0.2 points)\n"],"metadata":{"id":"8UUv-wZdOiqm"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"dLWRvvk_OiyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.2) Display the first 5 rows of the dataset (0.1 points)"],"metadata":{"id":"8HWf2vy-Oi-4"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"h-lCa70dOjHb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.3) What is the shape of the dataset (number of rows and columns)? (0.1 points)"],"metadata":{"id":"8X3BvvKOOjNv"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"s3kppvX2OjWw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.4) What are the column names and their data types? Use either `dtypes` or `.info()` or both (0.1 points)"],"metadata":{"id":"s2gjFOfzPEYr"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"BjHllubdPEgs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.5)Filter the rows such as `Ai_Assistant` is `ChatGPT` (0.3 points)"],"metadata":{"id":"jzbGzdJJPEmR"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"oBgXhwRkPEr1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.6) Filter the rows such as `Ai_Assistant` is `ChatGPT` and `Region` is `US` (0.3 points)"],"metadata":{"id":"EdKhUkcbPExW"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"ScKiRnKjPE3R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.7) Filter the rows such as:\n","\n","  - `Ai_Assistant` is `ChatGPT`\n","  \n","  - `Region` is `US`\n","  \n","  - `Type_of_question` is `Business`\n","\n","(0.3 points)"],"metadata":{"id":"Xra9XSgNPE8Y"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"la5wkgFbPFC6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.8) What was the total sum of `Revenue` in `US`, on `2025-05-01` for `Business` (`Type_of_question`) across all `AI_assistants`? (0.3 points)"],"metadata":{"id":"ULP8fg39rYBF"}},{"cell_type":"code","source":["# Your solution\n"],"metadata":{"id":"cClkQnmHrXoB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Aggregations"],"metadata":{"id":"Mgo8nZLWPFIW"}},{"cell_type":"markdown","source":["2.1) Create a pivot table to sum how many `Unique_users` are in each `Region`. Store the results in a dataframe called `df_region` (0.4 points)\n","\n","ðŸ’¡ *Hint: Recall the syntax for `pd.pivot_table(df,index=,values=,aggfunc=)`"],"metadata":{"id":"Oa9RgQCsR51c"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"_Xx-sW4-Q7p4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.2) In 2.1) The dataframe `df_region` should have the absolute frequency of `Unique_users`  per `Region`. Let's add a column with the **relative frequency**.\n","\n","For the dataframe `df_region` perform two computations:\n","\n","- **2.2.1)** Calculate the **total number of unique users** across all regions by summing the values in the `Unique_users` column.  \n","ðŸ’¡ *Hint: Use the `.sum()` method on the appropriate column.*\n","\n","- **2.2.2)** Using the total from the previous step, add a new column to `df_region` that contains the **relative frequency** (as a percentage) of `Unique_users` in each country.  \n","ðŸ’¡ *Hint: Divide the `Unique_users` count column by the total number of ``Unique_users` and multiply by 100.\n","\n","(0.4 points)"],"metadata":{"id":"WiXk2ch1SaY0"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"K2UKkyczSZua"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.3) Plot in an appropiate chart (either bar chart or pie chart) the relative proportion that each Region represents from exercise 2.2) . Either use matplotlib or seaborn (0.4 points)"],"metadata":{"id":"grUZ0B3CS6sL"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"bc6OoAcgS6AE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.4) Explore the relationship between **Number_of_queries** and **Unique_users**.\n","Create a scatter plot to visualize the relationship between **Number_of_queries** and **Unique_users** using the `df` DataFrame.\n","\n","ðŸ’¡ Hint: Use `plt.scatter()` from matplotlib.pyplot. Don't forget to add labels to the axes using `plt.xlabel()` and `plt.ylabel()` to make the chart easier to interpret.\n","\n","(0.4 points)\n"],"metadata":{"id":"bqTyJpYSUkEH"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"A8Dj1NY8UvtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.5) Does the previous plot suggest a positive relationship between  **Number_of_queries** and **Unique_users**?\n","\n","To prove it analytically, compute the correlation coefficient between the variables **Number_of_queries** and **Unique_users**.\n","\n","ðŸ’¡ Hint: You can use either the .corr() method in pandas or np.corrcoef() from NumPy.\n","\n","(0.4 points)"],"metadata":{"id":"b3HFrCusU5aa"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"NwsSRcDYVCvF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Regional Usage Analysis â€“ Most Used AI Assistants**\n","\n","2.6) Letâ€™s perform a geographic breakdown to better understand usage patterns across regions.\n","\n","Your task is to identify which `AI_Assistant` is the most used in terms of total `Number_of_queries` in selected regions.\n","\n","Create a pivot table showing the total sum of `Number_of_queries` per combination of `Region` and `AI_Assistant`.\n","\n","Based on this table, answer the following:\n","\n","- Which `AI_Assistant` has the highest sum of total `Number_of_queries`in the `US`?\n","\n","- Which `AI_Assistant` has the highest sum of total `Number_of_queries` in `Asia`?\n","\n","ðŸ’¡ *Hint: Recall the syntax for `pd.pivot_table(df,index=,values=,aggfunc=)`\n","\n","(0.4 points)"],"metadata":{"id":"B2GhXsngz-YY"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"BXY8uaLd8jxL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Cost Efficiency Analysis â€“ Which AI Assistant is the Most Efficient?**\n","\n","2.7) Let's identify which AI assistant is the most cost-efficient ðŸ’µ, based on the total cost per query across the dataset. Thus for each `AI_assistant` let's compute:\n","\n","$$\\text{Cost_per_query} = \\frac{\\text{Sum of total cost}}{\\text{Sum of Number of queries}} $$\n","\n","- Step 1: Create a pivot table capturing the sum of total `Number_of_queries` per `Ai_Assistant`. Store the information in a variable called `df_queries_total`.\n","\n","    ðŸ’¡ *Hint: Recall the syntax for `pd.pivot_table(df,index=,values=,aggfunc=)`\n","\n","- Step 2: Create a second pivot table capturing the sum of cost (`Cost_of_all_queries`) per `Ai_Assistant`. Store the information in a variable called `df_cost`.\n","\n","    ðŸ’¡ *Hint: Recall the syntax for `pd.pivot_table(df,index=,values=,aggfunc=)`\n","\n","- Step 3: Divide the total cost by the total number of queries for each assistant to calculate the average cost per query. To do so execute\n","\n","  ```python\n","  df_cost['Cost_of_all_queries'] / df_queries_total['Number_of_queries']\n","  ```\n","\n","Based on this analysis, which AI_Assistant has the lowest cost per query?\n","\n","(0.4 points)\n"],"metadata":{"id":"Jj3sKWcg9Zdb"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"KE2UXheR2urY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.8) Create a pivot table to compute the total `Number_of_queries` per day (`Date`) variable. Plot the resulting table in line chart. Use `plt.plot()`\n","\n","ðŸ’¡ *Hint: Recall the syntax for `pd.pivot_table(df,index=,values=,aggfunc=)`\n","\n","(0.4 points)"],"metadata":{"id":"orGmw8SnYw4p"}},{"cell_type":"code","source":["# Your solution"],"metadata":{"id":"1w5zF4H2CMdy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PARAao5LwKQz"},"execution_count":null,"outputs":[]}]}